{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4c343e-c695-47ea-b793-92e73465acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d86d1d-120b-4c71-baea-fa26d349f1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('AMES_Final_DF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c415e56-76ea-4820-ab0f-c9ffc981d312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>...</th>\n",
       "      <th>Sale Type_ConLw</th>\n",
       "      <th>Sale Type_New</th>\n",
       "      <th>Sale Type_Oth</th>\n",
       "      <th>Sale Type_VWD</th>\n",
       "      <th>Sale Type_WD</th>\n",
       "      <th>Sale Condition_AdjLand</th>\n",
       "      <th>Sale Condition_Alloca</th>\n",
       "      <th>Sale Condition_Family</th>\n",
       "      <th>Sale Condition_Normal</th>\n",
       "      <th>Sale Condition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>112.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1968</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lot Frontage  Lot Area  Overall Qual  Overall Cond  Year Built  \\\n",
       "0         141.0     31770             6             5        1960   \n",
       "1          80.0     11622             5             6        1961   \n",
       "2          81.0     14267             6             6        1958   \n",
       "3          93.0     11160             7             5        1968   \n",
       "4          74.0     13830             5             5        1997   \n",
       "\n",
       "   Year Remod/Add  Mas Vnr Area  BsmtFin SF 1  BsmtFin SF 2  Bsmt Unf SF  ...  \\\n",
       "0            1960         112.0         639.0           0.0        441.0  ...   \n",
       "1            1961           0.0         468.0         144.0        270.0  ...   \n",
       "2            1958         108.0         923.0           0.0        406.0  ...   \n",
       "3            1968           0.0        1065.0           0.0       1045.0  ...   \n",
       "4            1998           0.0         791.0           0.0        137.0  ...   \n",
       "\n",
       "   Sale Type_ConLw  Sale Type_New  Sale Type_Oth  Sale Type_VWD  \\\n",
       "0                0              0              0              0   \n",
       "1                0              0              0              0   \n",
       "2                0              0              0              0   \n",
       "3                0              0              0              0   \n",
       "4                0              0              0              0   \n",
       "\n",
       "   Sale Type_WD   Sale Condition_AdjLand  Sale Condition_Alloca  \\\n",
       "0              1                       0                      0   \n",
       "1              1                       0                      0   \n",
       "2              1                       0                      0   \n",
       "3              1                       0                      0   \n",
       "4              1                       0                      0   \n",
       "\n",
       "   Sale Condition_Family  Sale Condition_Normal  Sale Condition_Partial  \n",
       "0                      0                      1                       0  \n",
       "1                      0                      1                       0  \n",
       "2                      0                      1                       0  \n",
       "3                      0                      1                       0  \n",
       "4                      0                      1                       0  \n",
       "\n",
       "[5 rows x 274 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8bb54ed-018b-48d1-aa7b-6c4aad565762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2925 entries, 0 to 2924\n",
      "Columns: 274 entries, Lot Frontage to Sale Condition_Partial\n",
      "dtypes: float64(11), int64(263)\n",
      "memory usage: 6.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b84e1ca8-0265-4334-87ae-f5dbeae6158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('SalePrice',axis=1)\n",
    "y=df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd3c7b74-68c7-4880-a25f-8f4fbc265f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       215000\n",
       "1       105000\n",
       "2       172000\n",
       "3       244000\n",
       "4       189900\n",
       "         ...  \n",
       "2920    142500\n",
       "2921    131000\n",
       "2922    132000\n",
       "2923    170000\n",
       "2924    188000\n",
       "Name: SalePrice, Length: 2925, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efbf59ed-1d62-4cc6-923a-dffb0dba33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "305c4c74-2f03-4ed0-a2b7-0872aadd848c",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "315f5d8b-88cc-4f9c-85be-675325b0d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train= scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b04a0-84fb-404b-9e3a-392d03b99994",
   "metadata": {},
   "source": [
    "**We will use an Elastic Net model. Create an instance of default ElasticNet model with scikit-learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5e84224-ad98-4c29-8073-5f9964834b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e6b49ac-e4c9-4207-adbb-8116de35c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_elast_model = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e49f37b2-ef86-4fe5-9569-32517d7ddb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0.1,1,5,10,50,100],'l1_ratio':[.1,.5,.7,.95,.99,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc41e94c-bdac-475b-8942-3108c42a29cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a90a0382-68b1-4640-95b6-c34a33fae239",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(estimator=bas_elast_model,param_grid=param_grid,scoring='neg_mean_squared_error',cv=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2e90b02-fa11-47c1-bcee-93c4c0379b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.217e+11, tolerance: 1.356e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.491e+11, tolerance: 1.389e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.264e+11, tolerance: 1.285e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.285e+11, tolerance: 1.376e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.440e+11, tolerance: 1.406e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.519e+11, tolerance: 1.372e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.479e+11, tolerance: 1.380e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.434e+11, tolerance: 1.394e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.311e+11, tolerance: 1.342e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.274e+11, tolerance: 1.377e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.542e+11, tolerance: 1.356e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.782e+11, tolerance: 1.389e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.581e+11, tolerance: 1.285e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.712e+11, tolerance: 1.376e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.885e+11, tolerance: 1.406e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.904e+11, tolerance: 1.372e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.829e+11, tolerance: 1.380e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.797e+11, tolerance: 1.394e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.667e+11, tolerance: 1.342e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.743e+11, tolerance: 1.377e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.498e+11, tolerance: 1.356e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.736e+11, tolerance: 1.389e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.517e+11, tolerance: 1.285e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.683e+11, tolerance: 1.376e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+11, tolerance: 1.406e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.868e+11, tolerance: 1.372e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.788e+11, tolerance: 1.380e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.706e+11, tolerance: 1.394e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.607e+11, tolerance: 1.342e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.756e+11, tolerance: 1.377e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.855e+09, tolerance: 1.377e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.023e+11, tolerance: 1.356e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.130e+11, tolerance: 1.389e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.876e+11, tolerance: 1.285e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+11, tolerance: 1.376e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.031e+11, tolerance: 1.406e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e+11, tolerance: 1.372e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.186e+11, tolerance: 1.380e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+11, tolerance: 1.394e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.820e+11, tolerance: 1.342e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.196e+11, tolerance: 1.377e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+11, tolerance: 1.356e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e+11, tolerance: 1.389e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+11, tolerance: 1.285e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.921e+11, tolerance: 1.376e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.392e+11, tolerance: 1.406e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e+11, tolerance: 1.372e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+11, tolerance: 1.380e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+10, tolerance: 1.394e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+11, tolerance: 1.342e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+11, tolerance: 1.377e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+10, tolerance: 1.356e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.313e+10, tolerance: 1.389e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e+09, tolerance: 1.285e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.944e+10, tolerance: 1.376e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.074e+10, tolerance: 1.372e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.555e+10, tolerance: 1.380e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+10, tolerance: 1.377e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.1, 1, 5, 10, 50, 100],\n",
       "                         &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.7, 0.95, 0.99, 1]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.1, 1, 5, 10, 50, 100],\n",
       "                         &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.7, 0.95, 0.99, 1]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.1, 1, 5, 10, 50, 100],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.95, 0.99, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c0c0a91-d513-45a9-a989-296c9236e1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=100, l1_ratio=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=100, l1_ratio=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet(alpha=100, l1_ratio=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11f8688f-d188-4564-bee8-f13b32df87da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 100, 'l1_ratio': 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a628a82-faff-42b5-bfd7-af8e800187a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117375</td>\n",
       "      <td>0.021376</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.1}</td>\n",
       "      <td>-7.829558e+08</td>\n",
       "      <td>-4.441201e+08</td>\n",
       "      <td>-8.642549e+08</td>\n",
       "      <td>-4.709971e+08</td>\n",
       "      <td>-3.856357e+08</td>\n",
       "      <td>-3.720529e+08</td>\n",
       "      <td>-4.991273e+08</td>\n",
       "      <td>-4.112825e+08</td>\n",
       "      <td>-5.667919e+08</td>\n",
       "      <td>-4.711519e+08</td>\n",
       "      <td>-5.268370e+08</td>\n",
       "      <td>1.587834e+08</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.172715</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.5}</td>\n",
       "      <td>-7.802456e+08</td>\n",
       "      <td>-4.468126e+08</td>\n",
       "      <td>-8.126237e+08</td>\n",
       "      <td>-4.825996e+08</td>\n",
       "      <td>-3.835932e+08</td>\n",
       "      <td>-3.573702e+08</td>\n",
       "      <td>-4.847708e+08</td>\n",
       "      <td>-4.148016e+08</td>\n",
       "      <td>-5.653799e+08</td>\n",
       "      <td>-4.710669e+08</td>\n",
       "      <td>-5.199264e+08</td>\n",
       "      <td>1.489726e+08</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205601</td>\n",
       "      <td>0.030135</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.7}</td>\n",
       "      <td>-7.798928e+08</td>\n",
       "      <td>-4.521573e+08</td>\n",
       "      <td>-7.829182e+08</td>\n",
       "      <td>-4.929551e+08</td>\n",
       "      <td>-3.827021e+08</td>\n",
       "      <td>-3.502875e+08</td>\n",
       "      <td>-4.750711e+08</td>\n",
       "      <td>-4.197594e+08</td>\n",
       "      <td>-5.683098e+08</td>\n",
       "      <td>-4.730972e+08</td>\n",
       "      <td>-5.177150e+08</td>\n",
       "      <td>1.435986e+08</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279894</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.95}</td>\n",
       "      <td>-7.852374e+08</td>\n",
       "      <td>-4.714750e+08</td>\n",
       "      <td>-7.452372e+08</td>\n",
       "      <td>-5.221313e+08</td>\n",
       "      <td>-3.821716e+08</td>\n",
       "      <td>-3.485666e+08</td>\n",
       "      <td>-4.562478e+08</td>\n",
       "      <td>-4.311715e+08</td>\n",
       "      <td>-5.835802e+08</td>\n",
       "      <td>-4.792165e+08</td>\n",
       "      <td>-5.205035e+08</td>\n",
       "      <td>1.376539e+08</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.440311</td>\n",
       "      <td>0.194827</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.99}</td>\n",
       "      <td>-7.945166e+08</td>\n",
       "      <td>-4.803521e+08</td>\n",
       "      <td>-7.528844e+08</td>\n",
       "      <td>-5.333176e+08</td>\n",
       "      <td>-3.828807e+08</td>\n",
       "      <td>-3.508815e+08</td>\n",
       "      <td>-4.497926e+08</td>\n",
       "      <td>-4.236759e+08</td>\n",
       "      <td>-5.923347e+08</td>\n",
       "      <td>-4.793780e+08</td>\n",
       "      <td>-5.240014e+08</td>\n",
       "      <td>1.413069e+08</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.492547</td>\n",
       "      <td>0.063233</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 1}</td>\n",
       "      <td>-8.011976e+08</td>\n",
       "      <td>-4.851665e+08</td>\n",
       "      <td>-7.667847e+08</td>\n",
       "      <td>-5.378747e+08</td>\n",
       "      <td>-3.851658e+08</td>\n",
       "      <td>-3.523708e+08</td>\n",
       "      <td>-4.461442e+08</td>\n",
       "      <td>-4.275466e+08</td>\n",
       "      <td>-5.948065e+08</td>\n",
       "      <td>-4.885436e+08</td>\n",
       "      <td>-5.285601e+08</td>\n",
       "      <td>1.440981e+08</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.093738</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.1}</td>\n",
       "      <td>-9.381583e+08</td>\n",
       "      <td>-5.598217e+08</td>\n",
       "      <td>-1.475268e+09</td>\n",
       "      <td>-5.356517e+08</td>\n",
       "      <td>-4.354223e+08</td>\n",
       "      <td>-5.726021e+08</td>\n",
       "      <td>-6.851157e+08</td>\n",
       "      <td>-5.161454e+08</td>\n",
       "      <td>-7.677060e+08</td>\n",
       "      <td>-6.093833e+08</td>\n",
       "      <td>-7.095274e+08</td>\n",
       "      <td>2.892340e+08</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.132188</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>-8.541517e+08</td>\n",
       "      <td>-4.950661e+08</td>\n",
       "      <td>-1.221508e+09</td>\n",
       "      <td>-4.803796e+08</td>\n",
       "      <td>-4.086674e+08</td>\n",
       "      <td>-4.813120e+08</td>\n",
       "      <td>-5.986436e+08</td>\n",
       "      <td>-4.563991e+08</td>\n",
       "      <td>-6.651967e+08</td>\n",
       "      <td>-5.342342e+08</td>\n",
       "      <td>-6.195558e+08</td>\n",
       "      <td>2.350009e+08</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.153921</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.7}</td>\n",
       "      <td>-8.143279e+08</td>\n",
       "      <td>-4.648944e+08</td>\n",
       "      <td>-1.068091e+09</td>\n",
       "      <td>-4.626082e+08</td>\n",
       "      <td>-3.970389e+08</td>\n",
       "      <td>-4.327295e+08</td>\n",
       "      <td>-5.525812e+08</td>\n",
       "      <td>-4.283912e+08</td>\n",
       "      <td>-6.121032e+08</td>\n",
       "      <td>-4.981572e+08</td>\n",
       "      <td>-5.730922e+08</td>\n",
       "      <td>2.015749e+08</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.379920</td>\n",
       "      <td>0.092010</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.95}</td>\n",
       "      <td>-7.799697e+08</td>\n",
       "      <td>-4.466751e+08</td>\n",
       "      <td>-8.126396e+08</td>\n",
       "      <td>-4.822950e+08</td>\n",
       "      <td>-3.835581e+08</td>\n",
       "      <td>-3.573993e+08</td>\n",
       "      <td>-4.848706e+08</td>\n",
       "      <td>-4.147490e+08</td>\n",
       "      <td>-5.652733e+08</td>\n",
       "      <td>-4.708199e+08</td>\n",
       "      <td>-5.198249e+08</td>\n",
       "      <td>1.489482e+08</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.628409</td>\n",
       "      <td>0.087456</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.99}</td>\n",
       "      <td>-7.818068e+08</td>\n",
       "      <td>-4.649199e+08</td>\n",
       "      <td>-7.508778e+08</td>\n",
       "      <td>-5.123289e+08</td>\n",
       "      <td>-3.821034e+08</td>\n",
       "      <td>-3.469431e+08</td>\n",
       "      <td>-4.613647e+08</td>\n",
       "      <td>-4.290092e+08</td>\n",
       "      <td>-5.777724e+08</td>\n",
       "      <td>-4.774047e+08</td>\n",
       "      <td>-5.184531e+08</td>\n",
       "      <td>1.381121e+08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.697492</td>\n",
       "      <td>0.137042</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 1}</td>\n",
       "      <td>-7.991333e+08</td>\n",
       "      <td>-4.833520e+08</td>\n",
       "      <td>-7.628298e+08</td>\n",
       "      <td>-5.367942e+08</td>\n",
       "      <td>-3.845576e+08</td>\n",
       "      <td>-3.516660e+08</td>\n",
       "      <td>-4.464774e+08</td>\n",
       "      <td>-4.250232e+08</td>\n",
       "      <td>-5.938021e+08</td>\n",
       "      <td>-4.859138e+08</td>\n",
       "      <td>-5.269549e+08</td>\n",
       "      <td>1.434360e+08</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.050375</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.1}</td>\n",
       "      <td>-1.605015e+09</td>\n",
       "      <td>-1.075874e+09</td>\n",
       "      <td>-2.845280e+09</td>\n",
       "      <td>-1.084422e+09</td>\n",
       "      <td>-7.538096e+08</td>\n",
       "      <td>-1.259534e+09</td>\n",
       "      <td>-1.284310e+09</td>\n",
       "      <td>-9.841010e+08</td>\n",
       "      <td>-1.494763e+09</td>\n",
       "      <td>-1.186375e+09</td>\n",
       "      <td>-1.357348e+09</td>\n",
       "      <td>5.473195e+08</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.045778</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.5}</td>\n",
       "      <td>-1.255069e+09</td>\n",
       "      <td>-8.059429e+08</td>\n",
       "      <td>-2.199357e+09</td>\n",
       "      <td>-7.879088e+08</td>\n",
       "      <td>-5.692231e+08</td>\n",
       "      <td>-9.041307e+08</td>\n",
       "      <td>-9.787972e+08</td>\n",
       "      <td>-7.388028e+08</td>\n",
       "      <td>-1.118289e+09</td>\n",
       "      <td>-8.849043e+08</td>\n",
       "      <td>-1.024242e+09</td>\n",
       "      <td>4.325452e+08</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.045293</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.7}</td>\n",
       "      <td>-1.061719e+09</td>\n",
       "      <td>-6.559709e+08</td>\n",
       "      <td>-1.784597e+09</td>\n",
       "      <td>-6.301727e+08</td>\n",
       "      <td>-4.822913e+08</td>\n",
       "      <td>-7.028486e+08</td>\n",
       "      <td>-8.032762e+08</td>\n",
       "      <td>-6.033502e+08</td>\n",
       "      <td>-9.078682e+08</td>\n",
       "      <td>-7.177542e+08</td>\n",
       "      <td>-8.349849e+08</td>\n",
       "      <td>3.525243e+08</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.084226</td>\n",
       "      <td>0.007982</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.95}</td>\n",
       "      <td>-8.051749e+08</td>\n",
       "      <td>-4.581568e+08</td>\n",
       "      <td>-1.025740e+09</td>\n",
       "      <td>-4.601870e+08</td>\n",
       "      <td>-3.940461e+08</td>\n",
       "      <td>-4.200857e+08</td>\n",
       "      <td>-5.411831e+08</td>\n",
       "      <td>-4.221569e+08</td>\n",
       "      <td>-5.992810e+08</td>\n",
       "      <td>-4.898166e+08</td>\n",
       "      <td>-5.615828e+08</td>\n",
       "      <td>1.924250e+08</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.176704</td>\n",
       "      <td>0.030068</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.99}</td>\n",
       "      <td>-7.788331e+08</td>\n",
       "      <td>-4.461506e+08</td>\n",
       "      <td>-8.127506e+08</td>\n",
       "      <td>-4.809533e+08</td>\n",
       "      <td>-3.833862e+08</td>\n",
       "      <td>-3.576545e+08</td>\n",
       "      <td>-4.852983e+08</td>\n",
       "      <td>-4.143929e+08</td>\n",
       "      <td>-5.648701e+08</td>\n",
       "      <td>-4.697450e+08</td>\n",
       "      <td>-5.194035e+08</td>\n",
       "      <td>1.488582e+08</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.521830</td>\n",
       "      <td>0.050199</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 1}</td>\n",
       "      <td>-7.913073e+08</td>\n",
       "      <td>-4.781080e+08</td>\n",
       "      <td>-7.517239e+08</td>\n",
       "      <td>-5.320135e+08</td>\n",
       "      <td>-3.839337e+08</td>\n",
       "      <td>-3.490574e+08</td>\n",
       "      <td>-4.475575e+08</td>\n",
       "      <td>-4.227570e+08</td>\n",
       "      <td>-5.898039e+08</td>\n",
       "      <td>-4.782539e+08</td>\n",
       "      <td>-5.224516e+08</td>\n",
       "      <td>1.407827e+08</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.028013</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.1}</td>\n",
       "      <td>-2.261760e+09</td>\n",
       "      <td>-1.587065e+09</td>\n",
       "      <td>-3.893329e+09</td>\n",
       "      <td>-1.661402e+09</td>\n",
       "      <td>-1.157262e+09</td>\n",
       "      <td>-1.899972e+09</td>\n",
       "      <td>-1.845706e+09</td>\n",
       "      <td>-1.457294e+09</td>\n",
       "      <td>-2.213719e+09</td>\n",
       "      <td>-1.759629e+09</td>\n",
       "      <td>-1.973714e+09</td>\n",
       "      <td>7.122831e+08</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.030806</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.5}</td>\n",
       "      <td>-1.686598e+09</td>\n",
       "      <td>-1.138942e+09</td>\n",
       "      <td>-2.984269e+09</td>\n",
       "      <td>-1.154806e+09</td>\n",
       "      <td>-8.005155e+08</td>\n",
       "      <td>-1.340757e+09</td>\n",
       "      <td>-1.354540e+09</td>\n",
       "      <td>-1.041711e+09</td>\n",
       "      <td>-1.582994e+09</td>\n",
       "      <td>-1.256898e+09</td>\n",
       "      <td>-1.434203e+09</td>\n",
       "      <td>5.706063e+08</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.030133</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.7}</td>\n",
       "      <td>-1.347162e+09</td>\n",
       "      <td>-8.771375e+08</td>\n",
       "      <td>-2.379198e+09</td>\n",
       "      <td>-8.648286e+08</td>\n",
       "      <td>-6.149449e+08</td>\n",
       "      <td>-9.988587e+08</td>\n",
       "      <td>-1.060279e+09</td>\n",
       "      <td>-8.030627e+08</td>\n",
       "      <td>-1.217245e+09</td>\n",
       "      <td>-9.640722e+08</td>\n",
       "      <td>-1.112679e+09</td>\n",
       "      <td>4.656481e+08</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.065089</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.95}</td>\n",
       "      <td>-8.546574e+08</td>\n",
       "      <td>-4.955228e+08</td>\n",
       "      <td>-1.223206e+09</td>\n",
       "      <td>-4.800624e+08</td>\n",
       "      <td>-4.085412e+08</td>\n",
       "      <td>-4.822410e+08</td>\n",
       "      <td>-5.995962e+08</td>\n",
       "      <td>-4.564553e+08</td>\n",
       "      <td>-6.654879e+08</td>\n",
       "      <td>-5.344210e+08</td>\n",
       "      <td>-6.200192e+08</td>\n",
       "      <td>2.354246e+08</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.120221</td>\n",
       "      <td>0.012913</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.99}</td>\n",
       "      <td>-7.824605e+08</td>\n",
       "      <td>-4.438651e+08</td>\n",
       "      <td>-8.764379e+08</td>\n",
       "      <td>-4.666256e+08</td>\n",
       "      <td>-3.856760e+08</td>\n",
       "      <td>-3.765129e+08</td>\n",
       "      <td>-5.028379e+08</td>\n",
       "      <td>-4.101179e+08</td>\n",
       "      <td>-5.673050e+08</td>\n",
       "      <td>-4.699470e+08</td>\n",
       "      <td>-5.281786e+08</td>\n",
       "      <td>1.611376e+08</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.543704</td>\n",
       "      <td>0.119253</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 1}</td>\n",
       "      <td>-7.852644e+08</td>\n",
       "      <td>-4.752983e+08</td>\n",
       "      <td>-7.480698e+08</td>\n",
       "      <td>-5.275694e+08</td>\n",
       "      <td>-3.844735e+08</td>\n",
       "      <td>-3.463367e+08</td>\n",
       "      <td>-4.489566e+08</td>\n",
       "      <td>-4.293138e+08</td>\n",
       "      <td>-5.872985e+08</td>\n",
       "      <td>-4.752750e+08</td>\n",
       "      <td>-5.207856e+08</td>\n",
       "      <td>1.388371e+08</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.017658</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.1}</td>\n",
       "      <td>-4.656104e+09</td>\n",
       "      <td>-3.550086e+09</td>\n",
       "      <td>-7.139281e+09</td>\n",
       "      <td>-3.874579e+09</td>\n",
       "      <td>-2.925043e+09</td>\n",
       "      <td>-4.130379e+09</td>\n",
       "      <td>-3.899605e+09</td>\n",
       "      <td>-3.347893e+09</td>\n",
       "      <td>-4.921449e+09</td>\n",
       "      <td>-3.917063e+09</td>\n",
       "      <td>-4.236148e+09</td>\n",
       "      <td>1.113995e+09</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.5}</td>\n",
       "      <td>-3.728364e+09</td>\n",
       "      <td>-2.772946e+09</td>\n",
       "      <td>-5.938731e+09</td>\n",
       "      <td>-3.003956e+09</td>\n",
       "      <td>-2.203730e+09</td>\n",
       "      <td>-3.273827e+09</td>\n",
       "      <td>-3.099142e+09</td>\n",
       "      <td>-2.589293e+09</td>\n",
       "      <td>-3.865380e+09</td>\n",
       "      <td>-3.072634e+09</td>\n",
       "      <td>-3.354800e+09</td>\n",
       "      <td>9.798513e+08</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.017810</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.7}</td>\n",
       "      <td>-2.938499e+09</td>\n",
       "      <td>-2.126980e+09</td>\n",
       "      <td>-4.868851e+09</td>\n",
       "      <td>-2.274005e+09</td>\n",
       "      <td>-1.621638e+09</td>\n",
       "      <td>-2.539276e+09</td>\n",
       "      <td>-2.422575e+09</td>\n",
       "      <td>-1.967443e+09</td>\n",
       "      <td>-2.970908e+09</td>\n",
       "      <td>-2.360996e+09</td>\n",
       "      <td>-2.609117e+09</td>\n",
       "      <td>8.472686e+08</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.023498</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.95}</td>\n",
       "      <td>-1.258515e+09</td>\n",
       "      <td>-8.094695e+08</td>\n",
       "      <td>-2.206577e+09</td>\n",
       "      <td>-7.903029e+08</td>\n",
       "      <td>-5.710995e+08</td>\n",
       "      <td>-9.083144e+08</td>\n",
       "      <td>-9.830073e+08</td>\n",
       "      <td>-7.403881e+08</td>\n",
       "      <td>-1.121717e+09</td>\n",
       "      <td>-8.871555e+08</td>\n",
       "      <td>-1.027655e+09</td>\n",
       "      <td>4.339219e+08</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.050880</td>\n",
       "      <td>0.007685</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>50</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.99}</td>\n",
       "      <td>-8.571929e+08</td>\n",
       "      <td>-4.975187e+08</td>\n",
       "      <td>-1.231190e+09</td>\n",
       "      <td>-4.787309e+08</td>\n",
       "      <td>-4.087025e+08</td>\n",
       "      <td>-4.864609e+08</td>\n",
       "      <td>-6.042692e+08</td>\n",
       "      <td>-4.567013e+08</td>\n",
       "      <td>-6.670293e+08</td>\n",
       "      <td>-5.356002e+08</td>\n",
       "      <td>-6.223396e+08</td>\n",
       "      <td>2.373703e+08</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.415278</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 1}</td>\n",
       "      <td>-7.666413e+08</td>\n",
       "      <td>-4.575497e+08</td>\n",
       "      <td>-7.325873e+08</td>\n",
       "      <td>-5.032006e+08</td>\n",
       "      <td>-3.870638e+08</td>\n",
       "      <td>-3.399264e+08</td>\n",
       "      <td>-4.578867e+08</td>\n",
       "      <td>-4.298772e+08</td>\n",
       "      <td>-5.766485e+08</td>\n",
       "      <td>-4.677520e+08</td>\n",
       "      <td>-5.119134e+08</td>\n",
       "      <td>1.332559e+08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.019792</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.1}</td>\n",
       "      <td>-5.579914e+09</td>\n",
       "      <td>-4.339543e+09</td>\n",
       "      <td>-8.295921e+09</td>\n",
       "      <td>-4.750985e+09</td>\n",
       "      <td>-3.671762e+09</td>\n",
       "      <td>-4.981499e+09</td>\n",
       "      <td>-4.702646e+09</td>\n",
       "      <td>-4.126241e+09</td>\n",
       "      <td>-5.973622e+09</td>\n",
       "      <td>-4.764139e+09</td>\n",
       "      <td>-5.118627e+09</td>\n",
       "      <td>1.231945e+09</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.021148</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.5}</td>\n",
       "      <td>-4.816125e+09</td>\n",
       "      <td>-3.686016e+09</td>\n",
       "      <td>-7.342042e+09</td>\n",
       "      <td>-4.025736e+09</td>\n",
       "      <td>-3.052678e+09</td>\n",
       "      <td>-4.277789e+09</td>\n",
       "      <td>-4.038271e+09</td>\n",
       "      <td>-3.481068e+09</td>\n",
       "      <td>-5.103817e+09</td>\n",
       "      <td>-4.063322e+09</td>\n",
       "      <td>-4.388686e+09</td>\n",
       "      <td>1.135409e+09</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.023945</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.7}</td>\n",
       "      <td>-4.025849e+09</td>\n",
       "      <td>-3.020490e+09</td>\n",
       "      <td>-6.329067e+09</td>\n",
       "      <td>-3.281735e+09</td>\n",
       "      <td>-2.431363e+09</td>\n",
       "      <td>-3.548832e+09</td>\n",
       "      <td>-3.355093e+09</td>\n",
       "      <td>-2.829330e+09</td>\n",
       "      <td>-4.203768e+09</td>\n",
       "      <td>-3.342477e+09</td>\n",
       "      <td>-3.636800e+09</td>\n",
       "      <td>1.024980e+09</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.026333</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>100</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.95}</td>\n",
       "      <td>-1.695117e+09</td>\n",
       "      <td>-1.147095e+09</td>\n",
       "      <td>-2.998594e+09</td>\n",
       "      <td>-1.161363e+09</td>\n",
       "      <td>-8.058748e+08</td>\n",
       "      <td>-1.349408e+09</td>\n",
       "      <td>-1.362543e+09</td>\n",
       "      <td>-1.046256e+09</td>\n",
       "      <td>-1.591747e+09</td>\n",
       "      <td>-1.263305e+09</td>\n",
       "      <td>-1.442130e+09</td>\n",
       "      <td>5.730001e+08</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.040440</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.99}</td>\n",
       "      <td>-9.655076e+08</td>\n",
       "      <td>-5.819352e+08</td>\n",
       "      <td>-1.548993e+09</td>\n",
       "      <td>-5.528307e+08</td>\n",
       "      <td>-4.449595e+08</td>\n",
       "      <td>-6.042668e+08</td>\n",
       "      <td>-7.129721e+08</td>\n",
       "      <td>-5.331153e+08</td>\n",
       "      <td>-7.965786e+08</td>\n",
       "      <td>-6.310758e+08</td>\n",
       "      <td>-7.372234e+08</td>\n",
       "      <td>3.048496e+08</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.257447</td>\n",
       "      <td>0.026847</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 1}</td>\n",
       "      <td>-7.600362e+08</td>\n",
       "      <td>-4.461379e+08</td>\n",
       "      <td>-7.434255e+08</td>\n",
       "      <td>-4.808363e+08</td>\n",
       "      <td>-3.865327e+08</td>\n",
       "      <td>-3.451917e+08</td>\n",
       "      <td>-4.632576e+08</td>\n",
       "      <td>-4.225544e+08</td>\n",
       "      <td>-5.719481e+08</td>\n",
       "      <td>-4.607242e+08</td>\n",
       "      <td>-5.080645e+08</td>\n",
       "      <td>1.343131e+08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.117375      0.021376         0.001253        0.000403         0.1   \n",
       "1        0.172715      0.004392         0.001230        0.000374         0.1   \n",
       "2        0.205601      0.030135         0.001124        0.000297         0.1   \n",
       "3        0.279894      0.011194         0.001195        0.000401         0.1   \n",
       "4        0.440311      0.194827         0.001711        0.000518         0.1   \n",
       "5        0.492547      0.063233         0.002058        0.000348         0.1   \n",
       "6        0.093738      0.018476         0.002538        0.000834           1   \n",
       "7        0.132188      0.006966         0.002274        0.000502           1   \n",
       "8        0.153921      0.004913         0.003025        0.001113           1   \n",
       "9        0.379920      0.092010         0.004352        0.002220           1   \n",
       "10       0.628409      0.087456         0.002639        0.001742           1   \n",
       "11       0.697492      0.137042         0.002387        0.000866           1   \n",
       "12       0.050375      0.005681         0.003060        0.001887           5   \n",
       "13       0.045778      0.004476         0.001902        0.000706           5   \n",
       "14       0.045293      0.002080         0.002393        0.000755           5   \n",
       "15       0.084226      0.007982         0.001454        0.000568           5   \n",
       "16       0.176704      0.030068         0.001900        0.000831           5   \n",
       "17       0.521830      0.050199         0.002146        0.000770           5   \n",
       "18       0.028013      0.001939         0.001740        0.000439          10   \n",
       "19       0.030806      0.002621         0.002327        0.000637          10   \n",
       "20       0.030133      0.002678         0.001651        0.000554          10   \n",
       "21       0.065089      0.008933         0.001799        0.000404          10   \n",
       "22       0.120221      0.012913         0.002719        0.000851          10   \n",
       "23       0.543704      0.119253         0.002109        0.000958          10   \n",
       "24       0.017658      0.002412         0.001283        0.000450          50   \n",
       "25       0.017267      0.001917         0.001048        0.000350          50   \n",
       "26       0.017810      0.002591         0.001002        0.000632          50   \n",
       "27       0.023498      0.002334         0.001319        0.000483          50   \n",
       "28       0.050880      0.007685         0.001431        0.000559          50   \n",
       "29       0.415278      0.023719         0.001962        0.000367          50   \n",
       "30       0.019792      0.001637         0.001400        0.000489         100   \n",
       "31       0.021148      0.003530         0.001606        0.000546         100   \n",
       "32       0.023945      0.001858         0.001551        0.000471         100   \n",
       "33       0.026333      0.003086         0.001509        0.000493         100   \n",
       "34       0.040440      0.003639         0.001701        0.000457         100   \n",
       "35       0.257447      0.026847         0.001658        0.000678         100   \n",
       "\n",
       "   param_l1_ratio                            params  split0_test_score  \\\n",
       "0             0.1   {'alpha': 0.1, 'l1_ratio': 0.1}      -7.829558e+08   \n",
       "1             0.5   {'alpha': 0.1, 'l1_ratio': 0.5}      -7.802456e+08   \n",
       "2             0.7   {'alpha': 0.1, 'l1_ratio': 0.7}      -7.798928e+08   \n",
       "3            0.95  {'alpha': 0.1, 'l1_ratio': 0.95}      -7.852374e+08   \n",
       "4            0.99  {'alpha': 0.1, 'l1_ratio': 0.99}      -7.945166e+08   \n",
       "5               1     {'alpha': 0.1, 'l1_ratio': 1}      -8.011976e+08   \n",
       "6             0.1     {'alpha': 1, 'l1_ratio': 0.1}      -9.381583e+08   \n",
       "7             0.5     {'alpha': 1, 'l1_ratio': 0.5}      -8.541517e+08   \n",
       "8             0.7     {'alpha': 1, 'l1_ratio': 0.7}      -8.143279e+08   \n",
       "9            0.95    {'alpha': 1, 'l1_ratio': 0.95}      -7.799697e+08   \n",
       "10           0.99    {'alpha': 1, 'l1_ratio': 0.99}      -7.818068e+08   \n",
       "11              1       {'alpha': 1, 'l1_ratio': 1}      -7.991333e+08   \n",
       "12            0.1     {'alpha': 5, 'l1_ratio': 0.1}      -1.605015e+09   \n",
       "13            0.5     {'alpha': 5, 'l1_ratio': 0.5}      -1.255069e+09   \n",
       "14            0.7     {'alpha': 5, 'l1_ratio': 0.7}      -1.061719e+09   \n",
       "15           0.95    {'alpha': 5, 'l1_ratio': 0.95}      -8.051749e+08   \n",
       "16           0.99    {'alpha': 5, 'l1_ratio': 0.99}      -7.788331e+08   \n",
       "17              1       {'alpha': 5, 'l1_ratio': 1}      -7.913073e+08   \n",
       "18            0.1    {'alpha': 10, 'l1_ratio': 0.1}      -2.261760e+09   \n",
       "19            0.5    {'alpha': 10, 'l1_ratio': 0.5}      -1.686598e+09   \n",
       "20            0.7    {'alpha': 10, 'l1_ratio': 0.7}      -1.347162e+09   \n",
       "21           0.95   {'alpha': 10, 'l1_ratio': 0.95}      -8.546574e+08   \n",
       "22           0.99   {'alpha': 10, 'l1_ratio': 0.99}      -7.824605e+08   \n",
       "23              1      {'alpha': 10, 'l1_ratio': 1}      -7.852644e+08   \n",
       "24            0.1    {'alpha': 50, 'l1_ratio': 0.1}      -4.656104e+09   \n",
       "25            0.5    {'alpha': 50, 'l1_ratio': 0.5}      -3.728364e+09   \n",
       "26            0.7    {'alpha': 50, 'l1_ratio': 0.7}      -2.938499e+09   \n",
       "27           0.95   {'alpha': 50, 'l1_ratio': 0.95}      -1.258515e+09   \n",
       "28           0.99   {'alpha': 50, 'l1_ratio': 0.99}      -8.571929e+08   \n",
       "29              1      {'alpha': 50, 'l1_ratio': 1}      -7.666413e+08   \n",
       "30            0.1   {'alpha': 100, 'l1_ratio': 0.1}      -5.579914e+09   \n",
       "31            0.5   {'alpha': 100, 'l1_ratio': 0.5}      -4.816125e+09   \n",
       "32            0.7   {'alpha': 100, 'l1_ratio': 0.7}      -4.025849e+09   \n",
       "33           0.95  {'alpha': 100, 'l1_ratio': 0.95}      -1.695117e+09   \n",
       "34           0.99  {'alpha': 100, 'l1_ratio': 0.99}      -9.655076e+08   \n",
       "35              1     {'alpha': 100, 'l1_ratio': 1}      -7.600362e+08   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0       -4.441201e+08      -8.642549e+08      -4.709971e+08   \n",
       "1       -4.468126e+08      -8.126237e+08      -4.825996e+08   \n",
       "2       -4.521573e+08      -7.829182e+08      -4.929551e+08   \n",
       "3       -4.714750e+08      -7.452372e+08      -5.221313e+08   \n",
       "4       -4.803521e+08      -7.528844e+08      -5.333176e+08   \n",
       "5       -4.851665e+08      -7.667847e+08      -5.378747e+08   \n",
       "6       -5.598217e+08      -1.475268e+09      -5.356517e+08   \n",
       "7       -4.950661e+08      -1.221508e+09      -4.803796e+08   \n",
       "8       -4.648944e+08      -1.068091e+09      -4.626082e+08   \n",
       "9       -4.466751e+08      -8.126396e+08      -4.822950e+08   \n",
       "10      -4.649199e+08      -7.508778e+08      -5.123289e+08   \n",
       "11      -4.833520e+08      -7.628298e+08      -5.367942e+08   \n",
       "12      -1.075874e+09      -2.845280e+09      -1.084422e+09   \n",
       "13      -8.059429e+08      -2.199357e+09      -7.879088e+08   \n",
       "14      -6.559709e+08      -1.784597e+09      -6.301727e+08   \n",
       "15      -4.581568e+08      -1.025740e+09      -4.601870e+08   \n",
       "16      -4.461506e+08      -8.127506e+08      -4.809533e+08   \n",
       "17      -4.781080e+08      -7.517239e+08      -5.320135e+08   \n",
       "18      -1.587065e+09      -3.893329e+09      -1.661402e+09   \n",
       "19      -1.138942e+09      -2.984269e+09      -1.154806e+09   \n",
       "20      -8.771375e+08      -2.379198e+09      -8.648286e+08   \n",
       "21      -4.955228e+08      -1.223206e+09      -4.800624e+08   \n",
       "22      -4.438651e+08      -8.764379e+08      -4.666256e+08   \n",
       "23      -4.752983e+08      -7.480698e+08      -5.275694e+08   \n",
       "24      -3.550086e+09      -7.139281e+09      -3.874579e+09   \n",
       "25      -2.772946e+09      -5.938731e+09      -3.003956e+09   \n",
       "26      -2.126980e+09      -4.868851e+09      -2.274005e+09   \n",
       "27      -8.094695e+08      -2.206577e+09      -7.903029e+08   \n",
       "28      -4.975187e+08      -1.231190e+09      -4.787309e+08   \n",
       "29      -4.575497e+08      -7.325873e+08      -5.032006e+08   \n",
       "30      -4.339543e+09      -8.295921e+09      -4.750985e+09   \n",
       "31      -3.686016e+09      -7.342042e+09      -4.025736e+09   \n",
       "32      -3.020490e+09      -6.329067e+09      -3.281735e+09   \n",
       "33      -1.147095e+09      -2.998594e+09      -1.161363e+09   \n",
       "34      -5.819352e+08      -1.548993e+09      -5.528307e+08   \n",
       "35      -4.461379e+08      -7.434255e+08      -4.808363e+08   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0       -3.856357e+08      -3.720529e+08      -4.991273e+08   \n",
       "1       -3.835932e+08      -3.573702e+08      -4.847708e+08   \n",
       "2       -3.827021e+08      -3.502875e+08      -4.750711e+08   \n",
       "3       -3.821716e+08      -3.485666e+08      -4.562478e+08   \n",
       "4       -3.828807e+08      -3.508815e+08      -4.497926e+08   \n",
       "5       -3.851658e+08      -3.523708e+08      -4.461442e+08   \n",
       "6       -4.354223e+08      -5.726021e+08      -6.851157e+08   \n",
       "7       -4.086674e+08      -4.813120e+08      -5.986436e+08   \n",
       "8       -3.970389e+08      -4.327295e+08      -5.525812e+08   \n",
       "9       -3.835581e+08      -3.573993e+08      -4.848706e+08   \n",
       "10      -3.821034e+08      -3.469431e+08      -4.613647e+08   \n",
       "11      -3.845576e+08      -3.516660e+08      -4.464774e+08   \n",
       "12      -7.538096e+08      -1.259534e+09      -1.284310e+09   \n",
       "13      -5.692231e+08      -9.041307e+08      -9.787972e+08   \n",
       "14      -4.822913e+08      -7.028486e+08      -8.032762e+08   \n",
       "15      -3.940461e+08      -4.200857e+08      -5.411831e+08   \n",
       "16      -3.833862e+08      -3.576545e+08      -4.852983e+08   \n",
       "17      -3.839337e+08      -3.490574e+08      -4.475575e+08   \n",
       "18      -1.157262e+09      -1.899972e+09      -1.845706e+09   \n",
       "19      -8.005155e+08      -1.340757e+09      -1.354540e+09   \n",
       "20      -6.149449e+08      -9.988587e+08      -1.060279e+09   \n",
       "21      -4.085412e+08      -4.822410e+08      -5.995962e+08   \n",
       "22      -3.856760e+08      -3.765129e+08      -5.028379e+08   \n",
       "23      -3.844735e+08      -3.463367e+08      -4.489566e+08   \n",
       "24      -2.925043e+09      -4.130379e+09      -3.899605e+09   \n",
       "25      -2.203730e+09      -3.273827e+09      -3.099142e+09   \n",
       "26      -1.621638e+09      -2.539276e+09      -2.422575e+09   \n",
       "27      -5.710995e+08      -9.083144e+08      -9.830073e+08   \n",
       "28      -4.087025e+08      -4.864609e+08      -6.042692e+08   \n",
       "29      -3.870638e+08      -3.399264e+08      -4.578867e+08   \n",
       "30      -3.671762e+09      -4.981499e+09      -4.702646e+09   \n",
       "31      -3.052678e+09      -4.277789e+09      -4.038271e+09   \n",
       "32      -2.431363e+09      -3.548832e+09      -3.355093e+09   \n",
       "33      -8.058748e+08      -1.349408e+09      -1.362543e+09   \n",
       "34      -4.449595e+08      -6.042668e+08      -7.129721e+08   \n",
       "35      -3.865327e+08      -3.451917e+08      -4.632576e+08   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0       -4.112825e+08      -5.667919e+08      -4.711519e+08    -5.268370e+08   \n",
       "1       -4.148016e+08      -5.653799e+08      -4.710669e+08    -5.199264e+08   \n",
       "2       -4.197594e+08      -5.683098e+08      -4.730972e+08    -5.177150e+08   \n",
       "3       -4.311715e+08      -5.835802e+08      -4.792165e+08    -5.205035e+08   \n",
       "4       -4.236759e+08      -5.923347e+08      -4.793780e+08    -5.240014e+08   \n",
       "5       -4.275466e+08      -5.948065e+08      -4.885436e+08    -5.285601e+08   \n",
       "6       -5.161454e+08      -7.677060e+08      -6.093833e+08    -7.095274e+08   \n",
       "7       -4.563991e+08      -6.651967e+08      -5.342342e+08    -6.195558e+08   \n",
       "8       -4.283912e+08      -6.121032e+08      -4.981572e+08    -5.730922e+08   \n",
       "9       -4.147490e+08      -5.652733e+08      -4.708199e+08    -5.198249e+08   \n",
       "10      -4.290092e+08      -5.777724e+08      -4.774047e+08    -5.184531e+08   \n",
       "11      -4.250232e+08      -5.938021e+08      -4.859138e+08    -5.269549e+08   \n",
       "12      -9.841010e+08      -1.494763e+09      -1.186375e+09    -1.357348e+09   \n",
       "13      -7.388028e+08      -1.118289e+09      -8.849043e+08    -1.024242e+09   \n",
       "14      -6.033502e+08      -9.078682e+08      -7.177542e+08    -8.349849e+08   \n",
       "15      -4.221569e+08      -5.992810e+08      -4.898166e+08    -5.615828e+08   \n",
       "16      -4.143929e+08      -5.648701e+08      -4.697450e+08    -5.194035e+08   \n",
       "17      -4.227570e+08      -5.898039e+08      -4.782539e+08    -5.224516e+08   \n",
       "18      -1.457294e+09      -2.213719e+09      -1.759629e+09    -1.973714e+09   \n",
       "19      -1.041711e+09      -1.582994e+09      -1.256898e+09    -1.434203e+09   \n",
       "20      -8.030627e+08      -1.217245e+09      -9.640722e+08    -1.112679e+09   \n",
       "21      -4.564553e+08      -6.654879e+08      -5.344210e+08    -6.200192e+08   \n",
       "22      -4.101179e+08      -5.673050e+08      -4.699470e+08    -5.281786e+08   \n",
       "23      -4.293138e+08      -5.872985e+08      -4.752750e+08    -5.207856e+08   \n",
       "24      -3.347893e+09      -4.921449e+09      -3.917063e+09    -4.236148e+09   \n",
       "25      -2.589293e+09      -3.865380e+09      -3.072634e+09    -3.354800e+09   \n",
       "26      -1.967443e+09      -2.970908e+09      -2.360996e+09    -2.609117e+09   \n",
       "27      -7.403881e+08      -1.121717e+09      -8.871555e+08    -1.027655e+09   \n",
       "28      -4.567013e+08      -6.670293e+08      -5.356002e+08    -6.223396e+08   \n",
       "29      -4.298772e+08      -5.766485e+08      -4.677520e+08    -5.119134e+08   \n",
       "30      -4.126241e+09      -5.973622e+09      -4.764139e+09    -5.118627e+09   \n",
       "31      -3.481068e+09      -5.103817e+09      -4.063322e+09    -4.388686e+09   \n",
       "32      -2.829330e+09      -4.203768e+09      -3.342477e+09    -3.636800e+09   \n",
       "33      -1.046256e+09      -1.591747e+09      -1.263305e+09    -1.442130e+09   \n",
       "34      -5.331153e+08      -7.965786e+08      -6.310758e+08    -7.372234e+08   \n",
       "35      -4.225544e+08      -5.719481e+08      -4.607242e+08    -5.080645e+08   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0     1.587834e+08               12  \n",
       "1     1.489726e+08                7  \n",
       "2     1.435986e+08                3  \n",
       "3     1.376539e+08                8  \n",
       "4     1.413069e+08               11  \n",
       "5     1.440981e+08               15  \n",
       "6     2.892340e+08               21  \n",
       "7     2.350009e+08               18  \n",
       "8     2.015749e+08               17  \n",
       "9     1.489482e+08                6  \n",
       "10    1.381121e+08                4  \n",
       "11    1.434360e+08               13  \n",
       "12    5.473195e+08               27  \n",
       "13    4.325452e+08               24  \n",
       "14    3.525243e+08               23  \n",
       "15    1.924250e+08               16  \n",
       "16    1.488582e+08                5  \n",
       "17    1.407827e+08               10  \n",
       "18    7.122831e+08               30  \n",
       "19    5.706063e+08               28  \n",
       "20    4.656481e+08               26  \n",
       "21    2.354246e+08               19  \n",
       "22    1.611376e+08               14  \n",
       "23    1.388371e+08                9  \n",
       "24    1.113995e+09               34  \n",
       "25    9.798513e+08               32  \n",
       "26    8.472686e+08               31  \n",
       "27    4.339219e+08               25  \n",
       "28    2.373703e+08               20  \n",
       "29    1.332559e+08                2  \n",
       "30    1.231945e+09               36  \n",
       "31    1.135409e+09               35  \n",
       "32    1.024980e+09               33  \n",
       "33    5.730001e+08               29  \n",
       "34    3.048496e+08               22  \n",
       "35    1.343131e+08                1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_model.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f10816-8236-42cd-9630-7066486212ef",
   "metadata": {},
   "source": [
    "**Evaluate my model performance on the unseen 20% scaled test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17bd7efa-3b84-4739-a07f-2548ba868b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a429ea3-1494-4015-867a-52994ffee18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79dd65b2-b15b-4046-8655-fd7d03fd93a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14357.173348816375"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4bd8f7b-16ce-4948-a8f7-a6140add115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22024.688397037873"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e6888f3-8350-416e-914e-695b22efaf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180815.53743589742"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f98e3-7e39-48f9-890b-2781a7e30b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
